{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e1443ea-c891-4cf7-8c54-6e1ae27cd2d1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('HomeGoals', 'HomeTeamGoals'), ('AwayGoals', 'AwayTeamGoals'), ('Final', 'FinalResult')]\n"
     ]
    }
   ],
   "source": [
    "new_cols = ['HomeTeamGoals','AwayTeamGoals','FinalResult']\n",
    "old_cols = ['HomeGoals','AwayGoals','Final']\n",
    "\n",
    "cols = [*zip(old_cols,new_cols)]\n",
    "\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b0bc38f-e58d-46e6-a278-f574a3cf0926",
     "showTitle": true,
     "title": "WordCount PySpark - Using RDD"
    }
   },
   "outputs": [],
   "source": [
    "rdd_file = sc.textFile(\"dbfs:/FileStore/shared_uploads/brijeshpatel4547@gmail.com/data.txt\")\n",
    "rdd_lines = rdd_file.flatMap(lambda f : f.split(\" \"))\n",
    "rdd_words =  rdd_lines.map(lambda x: (x,1))\n",
    "rdd_count = rdd_words.reduceByKey(lambda x,y : x+y)\n",
    "rdd_sorted = rdd_count.sortBy(lambda x : x[1]).collect()\n",
    "rdd_sorted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "603ad118-1287-4d3d-89ec-b0a9d4c2b44c",
     "showTitle": true,
     "title": "WordCount PySpark - Using DataFrame"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n|      word|count|\n+----------+-----+\n|    anyone|   27|\n|       for|   27|\n|      with|   27|\n|        is|   27|\n|       use|   27|\n|      cost|   27|\n|       the|   27|\n|  anywhere|   27|\n|       and|   27|\n|        of|   27|\n|        no|   27|\n|     eBook|   27|\n|        at|   27|\n|      This|   27|\n|        by|   18|\n|        in|   18|\n|     Lewis|   18|\n|Wonderland|   18|\n|Adventures|   18|\n|   Aliceâ€™s|   18|\n+----------+-----+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode,split,col\n",
    "from pyspark.sql import Row,Column\n",
    "file_df = spark.read.text(\"dbfs:/FileStore/shared_uploads/brijeshpatel4547@gmail.com/data.txt\")\n",
    "words_df = file_df.withColumn('word',explode(split(col('value'),' '))).drop(col('value'))\n",
    "count_df = words_df.groupBy('word').count().sort('count',ascending = False)\n",
    "count_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93a2643b-ce29-448c-8a77-d239e51a6f29",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "PySpark Functions",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
